{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b655fb",
   "metadata": {},
   "source": [
    "# Web Crawling\n",
    "Proses mengumpulkan data dari halaman web secara otomatis menggunakan program crawler/spider (seperti Googlebot). Hasilnya berupa salinan konten web untuk diindeks atau dianalisis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b5c28a",
   "metadata": {},
   "source": [
    "## Langkah-langkah mengerjakan\n",
    "Siapkan website untuk kalian crawling, dalam contoh kasus ini kita akan mengambil jurnal yang ada di website springer nature. Selanjutnya, buka website https://dev.springernature.com/ lalu buat akun untuk mendapat API yang kalian butuhkan (meta API), copy API paste ke kode yang telah kalian buat.\n",
    "\n",
    "Setelah itu, ketikkan kata kunci yang ingin kalian tampilkan run kode lalu akan muncul total hasil kata kunci yang telah diketikkan sebelumnya. Dan, buat kode untuk mengkonversikan output dari kode kalian menjadi file csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "391ee562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sprynger\n",
      "  Downloading sprynger-0.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from sprynger)\n",
      "  Downloading lxml-6.0.1-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from sprynger) (2.32.4)\n",
      "Requirement already satisfied: urllib3 in /home/codespace/.local/lib/python3.12/site-packages (from sprynger) (2.5.0)\n",
      "Requirement already satisfied: platformdirs in /home/codespace/.local/lib/python3.12/site-packages (from sprynger) (4.3.8)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->sprynger) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->sprynger) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->sprynger) (2025.7.9)\n",
      "Downloading sprynger-0.4.1-py3-none-any.whl (40 kB)\n",
      "Downloading lxml-6.0.1-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lxml, sprynger\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [sprynger]1/2\u001b[0m [sprynger]\n",
      "\u001b[1A\u001b[2KSuccessfully installed lxml-6.0.1 sprynger-0.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sprynger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf1fcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hasil: 1275\n",
      "\n",
      "DOI: 10.1007/s41060-023-00483-9\n",
      "Title: Artificial intelligence trend analysis in German business and politics: a web mining approach\n",
      "Abstract: Current research on trend detection in artificial intelligence (AI) mainly concerns academic data sources and industrial applications of AI. However, we argue that industrial trends are influenced by public perception and political decisions (e.g., through industry subsidies and grants) and should be reflected in political data sources. To investigate this hypothesis, we examine the AI trend development in German business and politics from 1998 to 2020. Therefore, we propose a web mining approach to collect a novel data set consisting of business and political data sources combining 1.07 million articles and documents. We identify 246 AI-related buzzwords extracted from various glossaries. We use them to conduct an extensive trend detection and analysis study on the collected data using machine learning-based approaches. This study successfully detects an AI trend and follows its evolution in business and political data sources over the past two decades. Moreover, we find a faster adoption of AI in business than in politics, with a considerable increase in policy discourse in recent years. Finally, we show that the collected data can be used for trend detection besides AI-related topics using topic clustering and the COVID-19 pandemic as examples.\n",
      "\n",
      "DOI: 10.1007/s10586-025-05382-1\n",
      "Title: Task offloading for multi-UAV asset edge computing with deep reinforcement learning\n",
      "Abstract: Mobile Edge Computing (MEC) addresses the demands of computation-intensive network services by providing processing capabilities at the network’s edge, reducing service latency. Unmanned Aerial Vehicles (UAVs) enhance MEC due to their flexibility, broad coverage, and reliable wireless communication. This paper investigates task offloading in a UAV-assisted MEC system with multiple collaborating UAVs, optimizing task allocation in binary offloading mode to enhance system efficiency. System performance is evaluated in terms of energy consumption and task delay, while the proposed framework jointly optimizes UAV trajectory design, binary offloading, computation resource allocation, and communication resource management to achieve better resource utilization. To overcome the limitations of traditional heuristic-based approaches, we propose an innovative Deep Reinforcement Learning (DRL)-based task offloading framework and conduct a comparative analysis of Deep Deterministic Policy Gradient with Distance to Task Location and Capability Matching (DDPG with DTLCM), Deep Q-Network (DQN), and Q-Learning. Our approach leverages DTLCM to enhance decision-making, allowing UAVs to assign tasks more intelligently by factoring in both their proximity to the task and their computational capabilities. Experimental results show that DDPG with DTLCM consistently outperforms both DQN and Q-Learning, delivering more stable task allocation and better adaptability in dynamic scenarios. While DQN is more stable than Q-Learning in high-dimensional state spaces, it still suffers from discretization constraints. In contrast, DDPG with DTLCM benefits from a continuous action space, enabling more flexible and fine-tuned decision-making. These insights underscore the strength of policy-gradient DRL methods, particularly when augmented with context-aware mechanisms like DTLCM, in advancing UAV-assisted MEC task scheduling and resource optimization.\n",
      "\n",
      "DOI: 10.1007/s42979-025-04141-8\n",
      "Title: Taxonomy of Opinion Mining, Approaches and Domain Applications: Future Research Direction\n",
      "Abstract: Opinion Mining (OM), or Sentiment Analysis (SA), is the computational examination of opinions, sentiments, or emotions directed towards entities such as products, services, topics or organisations. Opinions underpin nearly all human activities and play a pivotal role in shaping and enhancing our overall quality of life. Hence, OM emerges as a vital aspect of human existence. Numerous studies have explored OM applications, approaches, and methodologies. However, these studies are dispersed across diverse sources, impeding seamless access, evaluation, and a holistic perspective on practical applications, trends, approaches, and future research directions in OM. Recognising this gap in the literature, this study endeavours to fill the void by providing a harmonised and comprehensive review of OM through a systematic literature review, aggregating pertinent papers from reputable scholarly databases and sources. The study identifies nine distinct areas of OM applications in literature, which span Business, Natural Disaster, down to Health, Education, Security and Safety domains, shedding light on the landscape of sentiment analysis. It also explores potential applications of OM in domains such as Crime Prediction, Human Resources, and Governance, among others, which offers a pointer into the diverse future possibilities of SA. Delving into methodological approach preferences, the study reveals that the Hybrid method takes centre stage, commanding a 37.1% representation, followed by the Traditional Machine Learning (ML)-27.3%, Multimodal method- 15.4%, and Deep Learning (DL)-9.7%. This study shows that while recent studies are tilting towards advanced techniques of OM, such as the Hybrid, Multimodal, DL and so on, for better results, these methods are not without some setbacks. In conclusion, the study urges further exploration of underrepresented application areas such as Security and Safety domains, including Crime Prediction, Cyber Security, and Public Service, among others, to ensure a well-rounded development in applications of OM in the literature. This comprehensive analysis provides not only valuable insights into the current state of OM but also guides future research endeavours in this dynamic field.\n",
      "\n",
      "DOI: 10.1007/s10462-025-11203-z\n",
      "Title: Web Intelligence (WI) 3.0: in search of a better-connected world to create a future intelligent society\n",
      "Abstract: Over the past two decades, Web Intelligence (WI) has emerged as a key field driving the evolution of AI in the connected world, addressing the demands of a future intelligent society. This paper provides a comprehensive review of WI’s contributions since its inception in 2000, spanning three distinct phases: Wisdom World Wide Web (WI 1.0, 2000–2009), Wisdom Web of Things (WI 2.0, 2010–2017), and Wisdom Web of Everything (WI 3.0, since 2018). For each phase, we examine key advancements, challenges, and future directions from the perspectives of both intelligent machines and human experts, highlighting significant societal impacts. To advance WI research, we propose a large language model-based learning framework for topic analysis and trend prediction. Moving beyond single-perspective approaches, we emphasize the Connected Intelligence Ecosystem defined by the HIGH5 scheme comprising one goal, two twins, three fundamentals, four functions, and five services that are realized through WI 3.0. This vision serves as a bridge from localized models to a global reference framework for addressing sustainability challenges in future societies. To illustrate the real-world implications of WI 3.0, we present case studies focusing on brain-inspired research, particularly in the intersection of brain intelligence, brain health, and brainternet-fostering interdisciplinary collaboration across diverse research communities.\n",
      "\n",
      "DOI: 10.1007/s42979-025-03942-1\n",
      "Title: A Contemporary Framework for Detection of Phishing Website for Cyber Societal Safety\n",
      "Abstract: In today’s digital age, phishing is a significant threat. It is a clever approach in which propagation of a website is done, and customers are enticed to a false website where customers are asked to enter critical personal information. Phishing website detection is clever and successful method that uses data mining algorithms to categories and associate websites. Detecting phishing websites is challenging since most of these methods are unable of making a dynamically right judgement about whether an encountered website is a phishing website or not. To determine efficiency, accuracy, the rules created, and speed, all rules and variables for grading phishing websites, also their relationships, were described and categorized. These algorithms are created. To identify phishing websites, we utilize a hybrid approach that includes developing description framework models for resource and categorizing websites using group learning algorithms. We utilize supervised learning methods to train our software. This strategy receives a high favorable rating, which is certainly noteworthy. We also used software to eliminate features that would allow us to estimate the frequency of each job in the dataset, a random forest classifier to cope with missing data sets. Our method will detect by utilizing the URL of website as input, helping us to have a good understanding of the factors that influence detection. The approach should be chosen as it increases accuracy in most situations. We get promising accuracy when our system investigates the strength of the Random Forest Algorithm and ensemble learning techniques.\n",
      "\n",
      "DOI: 10.1007/s41471-025-00208-7\n",
      "Title: Collecting and Analyzing User-Generated Content for Decision Support in Marketing Management: An Overview of Methods and Use Cases\n",
      "Abstract: User-generated content (UGC) is generally understood as an expression of opinion in many forms (e.g., complaints, online customer reviews, posts, testimonials) and data types (e.g., text, image, audio, video, or a combination thereof) that has been created and made available by users of websites, platforms, and apps on the Internet. In the digital age, huge amounts of UGC are available. Since UGC often reflects evaluations of brands, products, services, and technologies, many consumers rely on UGC to support and secure their purchasing and/or usage decisions. But UGC also has significant value for marketing managers. UGC allows them to easily gain insights into consumer attitudes, preferences, and behaviors. In this article, we review the literature on UGC-based decision support from this managerial perspective and look closely at relevant methods. In particular, we discuss how to collect and analyze various types of UGC from websites, platforms, and apps. Traditional data analysis and machine learning based on feature extraction methods as well as discriminative and generative deep learning methods are discussed. Selected use cases across various marketing management decision areas (such as customer/market selection, brand management, product/service quality management, new product/service development) are summarized. We provide researchers and practitioners with a comprehensive understanding of the current state of UGC data collection and analysis and help them to leverage this powerful resource effectively. Moreover, we shed light on potential applications in managerial decision support and identify research questions for further exploration.\n",
      "\n",
      "DOI: 10.1007/s11227-025-06997-2\n",
      "Title: Mining transactional tree databases under homeomorphism\n",
      "Abstract: A key task in mining tree-structured data is finding frequent embedded tree patterns, which has two settings: the transactional setting and the per-occurrence setting. In the transactional setting, which is the focus of this paper, the crucial step is to decide whether a tree pattern is subtree homeomorphic to a database tree. Our extensive study on the properties of real-world tree-structured datasets reveals that while many vertices in a database tree may have the same label, no two vertices on the same path are identically labeled. In this paper, we exploit this property and propose a novel and efficient method for deciding whether a tree pattern is subtree homeomorphic to a database tree. Our algorithm is based on a compact data structure called EMET , which stores all information required for subtree homeomorphism. We propose an efficient algorithm to generate EMET s of larger patterns using EMET s of the smaller ones. Based on the proposed subtree homeomorphism method, we introduce TTM , an effective algorithm for finding frequent tree patterns from rooted ordered trees. We evaluate the efficiency of TTM on several real-world and synthetic datasets and show that it outperforms well-known existing algorithms by an order of magnitude.\n",
      "\n",
      "DOI: 10.1038/s44183-025-00104-x\n",
      "Title: Major data gaps and recommendations in monitoring regulations of activities in EU marine protected areas\n",
      "Abstract: Marine Protected Areas (MPAs) play a central role in maritime policies, but there are no comprehensive analyses of regulations in EU MPAs. Using publicly available data on EU MPAs’ regulations for nine activities, we first show that MPA and MSP databases display significant gaps in data comprehensiveness. The regulation of each activity was known in 40% or less of the MPA area (whether allowed, prohibited, or restricted), except for fishing activities (70% of MPA area), albeit with limited detail. Fishing, mining, or dredging/dumping activities were allowed in half of MPA area. Only mining was reported as prohibited in at least 10% of the MPA area. We discuss gaps in MPA regulatory data in light of existing reporting requirements, insufficient connection between various actors and data sources, and challenges in translating legal information into actionable indicators. We provide recommendations for future initiatives to improve the collection and standardization for environmental policies.\n",
      "\n",
      "DOI: 10.1007/978-981-96-0476-0_11\n",
      "Title: Pattern and Prediction Analysis by Using Different Data Mining Techniques for the Web Usage Data\n",
      "Abstract: Today’s world highly depends on the web pages, applications, internet in their day-to-day life. To better understand and meet the demands of web-based applications, web usage mining employs data mining approaches to identify usage patterns from web data. Preprocessing, pattern discovery, and pattern analysis are the three stages of web usage mining. This article provides a thorough explanation of pattern and prediction analysis based on web usage mining. The academic and industrial sectors have shown a significant increase in interest in web usage mining due to its potential for applications. This paper offers a thorough taxonomy of the work in this field, including research initiatives and current web usage patterns. A recent review of the work that has previously performed is also presented, considering various data mining methodologies including techniques for classification, regression analysis, and clustering. The limitations of web usage are then discussed and concluded.\n",
      "\n",
      "DOI: 10.1007/978-3-031-73699-5_16\n",
      "Title: NoCrypto: A Web Mining Behavior Detection Method Based on RGB Images\n",
      "Abstract: In recent years, there has been a growing prevalence of mining web pages using the new web technology of WebAssembly (WASM), resulting in the unauthorized exploitation of user resources. However, existing detection methods have shown limited ability to counter obfuscation techniques and have exhibited low detection efficiency. To address these issues, this paper proposes a novel static detection method based on the visualization of WASM modules. The proposed method involves instantiating the binary files of the WASM mining operations within web pages. These binary files are then combined with the information of local entropy and global entropy, resulting in the visualization of RGB images. Compared to grayscale images, RGB images retain more of the original file information. After training and learning the image features using a convolutional neural network (CNN), the model achieves an impressive accuracy rate of 99.18% when tested on real-world web pages. This accuracy is approximately 2% higher than that of existing visualization-based detection methods. Moreover, the model exhibits a shorter execution time. The proposed NoCrypto method demonstrates quick execution speed and accurate detection.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "# Silahkan membuat api key dari https://dev.springernature.com/#api\n",
    "api_key = \"4b25841b8ccff165e4b251048a414037\"\n",
    "isbn = \"978-3-031-63497-0\"\n",
    "\n",
    "url = \"https://api.springernature.com/meta/v2/json\"\n",
    "params = {\n",
    "    \"q\": f\"web mining,web usage mining\",\n",
    "    \"api_key\": api_key,\n",
    "    \"p\": 10\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(f\"Total hasil: {data['result'][0]['total']}\\n\")\n",
    "    for record in data['records']:\n",
    "        doi = record.get('doi', 'N/A')\n",
    "        title = record.get('title', 'No title')\n",
    "        abstract = record.get('abstract', 'No abstract')\n",
    "        print(f\"DOI: {doi}\")\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Abstract: {abstract}\\n\")\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18df90b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sukses: hasil disimpan di springer_results.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "api_key = \"4b25841b8ccff165e4b251048a414037\"\n",
    "\n",
    "url = \"https://api.springernature.com/meta/v2/json\"\n",
    "params = {\n",
    "    \"q\": \"Jokowi\",\n",
    "    \"api_key\": api_key,\n",
    "    \"p\": 10\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params, timeout=10)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "    # buka file CSV dan tulis header + rows\n",
    "    with open(\"springer_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        fieldnames = [\"doi\", \"title\", \"abstract\", \"publicationName\", \"isbn\", \"url\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for record in data.get(\"records\", []):\n",
    "            writer.writerow({\n",
    "                \"doi\": record.get(\"doi\", \"N/A\"),\n",
    "                \"title\": record.get(\"title\", \"No title\"),\n",
    "                \"abstract\": record.get(\"abstract\", \"No abstract\"),\n",
    "                \"publicationName\": record.get(\"publicationName\", \"\"),\n",
    "                \"isbn\": record.get(\"isbn\", \"\"),\n",
    "                \"url\": record.get(\"url\", \"\")\n",
    "            })\n",
    "\n",
    "    print(\"Sukses: hasil disimpan di springer_results.csv\")\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12056cd",
   "metadata": {},
   "source": [
    "## File csv otomatis tersimpan ke lokal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
